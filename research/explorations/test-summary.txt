ilo syntax comparison
==========================================================================================

  Idea                          Tokens   vs Py   Chars   vs Py   Score  Out tok
  --------------------------------------------------------------------------
  python-baseline                  871   1.00x    3635   1.00x       —        —  *
  idea1                            921   1.06x    3108   0.86x    10.0      344
  idea1-compact                    677   0.78x    2564   0.71x    10.0      225
  idea2-tool-calling               983   1.13x    3203   0.88x    10.0      360
  idea3-constrained-decoding       598   0.69x    2187   0.60x    10.0      220
  idea4-ast-bytecode               584   0.67x    1190   0.33x     9.8      318
  idea5-workflow-dag               710   0.82x    2603   0.72x    10.0      238
  idea6-mcp-composition            956   1.10x    2978   0.82x     9.5      316
  idea7-dense-wire                 351   0.40x    1292   0.36x    10.0      190
  idea8-ultra-dense                285   0.33x     901   0.25x    10.0       90
  idea9-ultra-dense-short          287   0.33x     787   0.22x    10.0       92

  Tokens  = total tokens across 5 examples (cl100k_base, comments stripped)
  Chars   = total characters
  Score   = LLM generation accuracy /10 (spec + all examples, claude-haiku-4-5)
  Out tok = avg output tokens generated
  * = baseline


Per-task breakdown (Full test)
==========================================================================================

  Idea                            workflow   data_pipe    decision    api_orch
  ------------------------------------------------------------------------
  idea1                              10.0       10.0       10.0       10.0
  idea1-compact                      10.0       10.0       10.0       10.0
  idea2-tool-calling                 10.0       10.0       10.0       10.0
  idea3-constrained-decoding         10.0       10.0       10.0       10.0
  idea4-ast-bytecode                 10.0       10.0        9.0       10.0
  idea5-workflow-dag                 10.0       10.0       10.0       10.0
  idea6-mcp-composition               9.0       10.0        9.0       10.0
  idea7-dense-wire                   10.0       10.0       10.0       10.0
  idea8-ultra-dense                  10.0       10.0       10.0       10.0
  idea9-ultra-dense-short            10.0       10.0       10.0       10.0


Benchmark: tot(10, 20, 30) — p*q + p*q*r = 6200
==========================================================================================
10,000 iterations, release build, Apple Silicon (aarch64)

  INTERPRETED                Per call
  ----------------------------------------------------------
  ilo interpreter            1,390 ns
  CPython                      226 ns
  ilo Register VM              139 ns
  ilo Python transpiled         92 ns
  ilo Register VM (reused)      69 ns
  Ruby                          43 ns
  PHP                           40 ns
  Lua                           30 ns

  JIT-COMPILED               Per call
  ----------------------------------------------------------
  Node.js / V8                  16 ns
  ilo Custom JIT (arm64)         2 ns
  ilo Cranelift JIT              2 ns
  LuaJIT                         2 ns
  PyPy3                        1.1 ns

  AOT-COMPILED               Per call
  ----------------------------------------------------------
  Go                             2 ns
  C (clang -O2)                0.4 ns
  Rust (rustc -O)              0.4 ns

  PER-IDEA (ilo backends only, all using tot/total with args 10 20 30 = 6200)
  ----------------------------------------------------------
  Idea                   Interpreter    Reg VM    VM reused    Custom JIT    Cranelift
  idea8-ultra-dense        1,401 ns     144 ns       74 ns         2 ns         2 ns
  idea9-ultra-dense-short  1,390 ns     139 ns       69 ns         2 ns         2 ns

  (idea1, idea1-compact, idea7 use syntax not yet supported by current parser)
  (idea8 and idea9 compile to identical bytecode — differences are run-to-run noise)

  Notes:
  - ilo Custom JIT and Cranelift JIT match LuaJIT and Go at ~2ns
  - Only C/Rust beat ilo JIT backends (compiler can eliminate the function call)
  - PyPy3 at 1.1ns after proper warmup (1M iterations, 10k warmup)
  - ilo Register VM (reused) competitive with Ruby/PHP/Lua interpreters
  - TypeScript runs on V8, same result as Node.js (16ns)
